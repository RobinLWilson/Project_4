{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VNdLEB5hjb9Y"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload csv file\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "cc7Oo-ZRkD1o",
        "outputId": "a6f2cea7-07a9-40ce-bd88-699869eea274"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e4f323b-16e0-4e4d-9e69-12bccd610543\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e4f323b-16e0-4e4d-9e69-12bccd610543\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving HR_Analytics_clean.csv to HR_Analytics_clean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import and read the csv.\n",
        "\n",
        "hr_dummies_df= pd.read_csv(\"HR_Analytics_clean.csv\")\n",
        "hr_dummies_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "q7WCjVaWkF7j",
        "outputId": "2399723d-b455-4192-e8a1-af21a59c8678"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      AgeGroup  Attrition  BusinessTravel  DistanceFromHome  Education  \\\n",
              "0            1          1               1                 3          3   \n",
              "1            1          0               1                10          3   \n",
              "2            1          1               2                 5          3   \n",
              "3            1          0               3                 5          2   \n",
              "4            1          1               3                 8          1   \n",
              "...        ...        ...             ...               ...        ...   \n",
              "1411         5          0               1                 7          3   \n",
              "1412         5          0               2                28          3   \n",
              "1413         5          0               1                16          4   \n",
              "1414         5          0               1                 7          4   \n",
              "1415         5          0               1                 1          4   \n",
              "\n",
              "      EnvironmentSatisfaction  Gender  JobInvolvement  JobLevel  \\\n",
              "0                           3       1               3         1   \n",
              "1                           4       0               2         1   \n",
              "2                           2       1               3         1   \n",
              "3                           2       1               3         1   \n",
              "4                           3       1               3         1   \n",
              "...                       ...     ...             ...       ...   \n",
              "1411                        1       0               3         5   \n",
              "1412                        3       0               2         3   \n",
              "1413                        1       1               3         2   \n",
              "1414                        2       1               4         2   \n",
              "1415                        3       1               1         3   \n",
              "\n",
              "      JobSatisfaction  ...  YearsWithCurrManager  Sales  Human_Resources  \\\n",
              "0                   3  ...                   0.0      0                0   \n",
              "1                   3  ...                   0.0      1                0   \n",
              "2                   2  ...                   0.0      1                0   \n",
              "3                   4  ...                   0.0      0                0   \n",
              "4                   3  ...                   0.0      0                0   \n",
              "...               ...  ...                   ...    ...              ...   \n",
              "1411                1  ...                  10.0      0                0   \n",
              "1412                1  ...                  11.0      3                0   \n",
              "1413                1  ...                   2.0      3                0   \n",
              "1414                4  ...                   9.0      3                0   \n",
              "1415                4  ...                   0.0      0                0   \n",
              "\n",
              "      Research_&_Development  EducationField_Human Resources  \\\n",
              "0                          2                           False   \n",
              "1                          0                           False   \n",
              "2                          0                           False   \n",
              "3                          3                           False   \n",
              "4                          2                           False   \n",
              "...                      ...                             ...   \n",
              "1411                       4                           False   \n",
              "1412                       0                           False   \n",
              "1413                       0                           False   \n",
              "1414                       0                           False   \n",
              "1415                       1                           False   \n",
              "\n",
              "      EducationField_Life Sciences  EducationField_Marketing  \\\n",
              "0                             True                     False   \n",
              "1                            False                     False   \n",
              "2                            False                      True   \n",
              "3                             True                     False   \n",
              "4                            False                     False   \n",
              "...                            ...                       ...   \n",
              "1411                          True                     False   \n",
              "1412                         False                      True   \n",
              "1413                         False                      True   \n",
              "1414                         False                      True   \n",
              "1415                         False                     False   \n",
              "\n",
              "      EducationField_Medical  EducationField_Other  \\\n",
              "0                      False                 False   \n",
              "1                       True                 False   \n",
              "2                      False                 False   \n",
              "3                      False                 False   \n",
              "4                       True                 False   \n",
              "...                      ...                   ...   \n",
              "1411                   False                 False   \n",
              "1412                   False                 False   \n",
              "1413                   False                 False   \n",
              "1414                   False                 False   \n",
              "1415                    True                 False   \n",
              "\n",
              "      EducationField_Technical Degree  \n",
              "0                               False  \n",
              "1                               False  \n",
              "2                               False  \n",
              "3                               False  \n",
              "4                               False  \n",
              "...                               ...  \n",
              "1411                            False  \n",
              "1412                            False  \n",
              "1413                            False  \n",
              "1414                            False  \n",
              "1415                            False  \n",
              "\n",
              "[1416 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc5dbc08-949a-491a-85b1-cf2f151b10da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AgeGroup</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>...</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Human_Resources</th>\n",
              "      <th>Research_&amp;_Development</th>\n",
              "      <th>EducationField_Human Resources</th>\n",
              "      <th>EducationField_Life Sciences</th>\n",
              "      <th>EducationField_Marketing</th>\n",
              "      <th>EducationField_Medical</th>\n",
              "      <th>EducationField_Other</th>\n",
              "      <th>EducationField_Technical Degree</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1411</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1412</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1413</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1414</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1415</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1416 rows × 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc5dbc08-949a-491a-85b1-cf2f151b10da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc5dbc08-949a-491a-85b1-cf2f151b10da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc5dbc08-949a-491a-85b1-cf2f151b10da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77129b98-47d5-4a2a-ad0f-41403310bc1c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77129b98-47d5-4a2a-ad0f-41403310bc1c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77129b98-47d5-4a2a-ad0f-41403310bc1c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4359af10-5563-4e2d-8df4-f8d9596f633c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('hr_dummies_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4359af10-5563-4e2d-8df4-f8d9596f633c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('hr_dummies_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "hr_dummies_df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X = hr_dummies_df.drop([\"Attrition\"], axis='columns')\n",
        "y = hr_dummies_df[\"Attrition\"]\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,random_state=78)"
      ],
      "metadata": {
        "id": "X80WmDzskIhC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the data\n",
        "# Create a MinMax instances\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "2IbLi3i6kKxn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#relu activation_______\n",
        "input_dimensions = len(X_train_scaled[0])\n",
        "hidden_layer_1 = 80\n",
        "hidden_layer_2 = 30\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_layer_1, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_layer_2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD4SsWo8ksxp",
        "outputId": "5a064c4d-5e71-41c6-a979-550edd681767"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 80)                2800      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5261 (20.55 KB)\n",
            "Trainable params: 5261 (20.55 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "#adam optimizer\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZGGEKXOUkxE1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idPfgwgMkzst",
        "outputId": "45fc4dd3-53c1-4600-ee48-22e2d1a986d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 1s 1ms/step - loss: 0.5283 - accuracy: 0.7553\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8383\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8383\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8481\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8648\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8657\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.8728\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8737\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8746\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.8781\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.8913\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8896\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.8940\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.8984\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2622 - accuracy: 0.9028\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 0.9046\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.9011\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.9072\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.9099\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9090\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.9125\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.9117\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9231\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.9223\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9249\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9231\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.9267\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.9240\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9329\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9364\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9320\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9373\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9373\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9382\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.9399\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9426\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9479\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9461\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9488\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9514\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9532\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9496\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9514\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9549\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9602\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9611\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9594\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9655\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9655\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9638\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9664\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9708\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9779\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9691\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9761\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9788\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9832\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9788\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9806\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9823\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9832\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9850\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9859\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9867\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9867\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9850\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9876\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9885\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9885\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9894\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9912\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9885\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9894\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9903\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9947\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9903\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9929\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9947\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9947\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9947\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9982\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9956\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9965\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9956\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9982\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9982\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9982\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9991\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9982\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9991\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9982\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9991\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9982\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.9982\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9991\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9991\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9991\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9991\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9982\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlfaOisqk1Rf",
        "outputId": "0b5e1b11-f343-43cf-eadf-c5d45003f17a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 0.9937 - accuracy: 0.8169 - 164ms/epoch - 18ms/step\n",
            "Loss: 0.9937062859535217, Accuracy: 0.8169013857841492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization #1\n",
        "- reduce epochs to 88 because at that point the accuracy began to flatten"
      ],
      "metadata": {
        "id": "eechkOen9vyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input_dimensions = len(X_train_scaled[0])\n",
        "hidden_layer_1 = 80\n",
        "hidden_layer_2 = 30\n",
        "\n",
        "nn1 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn1.add(tf.keras.layers.Dense(units=hidden_layer_1, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn1.add(tf.keras.layers.Dense(units=hidden_layer_2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsdaUt6z9nl2",
        "outputId": "e385eeac-94bc-43e8-832d-baf7bed08c1e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 80)                2800      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5261 (20.55 KB)\n",
            "Trainable params: 5261 (20.55 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "pJCu2xZ-9nxo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn1.fit(X_train_scaled, y_train, epochs=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emar7x7c9n5z",
        "outputId": "ab654c63-a2a5-4834-8cc6-3707522eab56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/88\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8383\n",
            "Epoch 2/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8383\n",
            "Epoch 3/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8489\n",
            "Epoch 4/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8622\n",
            "Epoch 5/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8710\n",
            "Epoch 6/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8754\n",
            "Epoch 7/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8825\n",
            "Epoch 8/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8834\n",
            "Epoch 9/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8834\n",
            "Epoch 10/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 0.8922\n",
            "Epoch 11/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8896\n",
            "Epoch 12/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8966\n",
            "Epoch 13/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9002\n",
            "Epoch 14/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2651 - accuracy: 0.8993\n",
            "Epoch 15/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.9028\n",
            "Epoch 16/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.9064\n",
            "Epoch 17/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.9099\n",
            "Epoch 18/88\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.9081\n",
            "Epoch 19/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9090\n",
            "Epoch 20/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.9170\n",
            "Epoch 21/88\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.2337 - accuracy: 0.9170\n",
            "Epoch 22/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9099\n",
            "Epoch 23/88\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.2275 - accuracy: 0.9170\n",
            "Epoch 24/88\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9161\n",
            "Epoch 25/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9196\n",
            "Epoch 26/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9267\n",
            "Epoch 27/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9284\n",
            "Epoch 28/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9231\n",
            "Epoch 29/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9346\n",
            "Epoch 30/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9337\n",
            "Epoch 31/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9346\n",
            "Epoch 32/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9373\n",
            "Epoch 33/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9390\n",
            "Epoch 34/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9408\n",
            "Epoch 35/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9399\n",
            "Epoch 36/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9337\n",
            "Epoch 37/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9426\n",
            "Epoch 38/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9479\n",
            "Epoch 39/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9488\n",
            "Epoch 40/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9523\n",
            "Epoch 41/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9549\n",
            "Epoch 42/88\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9549\n",
            "Epoch 43/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9585\n",
            "Epoch 44/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9567\n",
            "Epoch 45/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9532\n",
            "Epoch 46/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9611\n",
            "Epoch 47/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9638\n",
            "Epoch 48/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.9629\n",
            "Epoch 49/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9691\n",
            "Epoch 50/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9717\n",
            "Epoch 51/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9726\n",
            "Epoch 52/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.9726\n",
            "Epoch 53/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9700\n",
            "Epoch 54/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9735\n",
            "Epoch 55/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9735\n",
            "Epoch 56/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9770\n",
            "Epoch 57/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9806\n",
            "Epoch 58/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9797\n",
            "Epoch 59/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9814\n",
            "Epoch 60/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9797\n",
            "Epoch 61/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9850\n",
            "Epoch 62/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9832\n",
            "Epoch 63/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9876\n",
            "Epoch 64/88\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9876\n",
            "Epoch 65/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9894\n",
            "Epoch 66/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9885\n",
            "Epoch 67/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9894\n",
            "Epoch 68/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9876\n",
            "Epoch 69/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9929\n",
            "Epoch 70/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9947\n",
            "Epoch 71/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9938\n",
            "Epoch 72/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9929\n",
            "Epoch 73/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9938\n",
            "Epoch 74/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9938\n",
            "Epoch 75/88\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9965\n",
            "Epoch 76/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9956\n",
            "Epoch 77/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9956\n",
            "Epoch 78/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9947\n",
            "Epoch 79/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9956\n",
            "Epoch 80/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9973\n",
            "Epoch 81/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9973\n",
            "Epoch 82/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9956\n",
            "Epoch 83/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9965\n",
            "Epoch 84/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9973\n",
            "Epoch 85/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9982\n",
            "Epoch 86/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9982\n",
            "Epoch 87/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9973\n",
            "Epoch 88/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn1.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a-HBbAd9n__",
        "outputId": "46fff05d-67f5-4677-96ee-2e701306cb7f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 0.8599 - accuracy: 0.8415 - 90ms/epoch - 10ms/step\n",
            "Loss: 0.8599094152450562, Accuracy: 0.841549277305603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization #2\n",
        "- add a hidden layer so the model can increase its ability to learn complex patterns\n"
      ],
      "metadata": {
        "id": "1yU8mCE3_VpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input_dimensions = len(X_train_scaled[0])\n",
        "hidden_layer_1 = 80\n",
        "hidden_layer_2 = 30\n",
        "hidden_layer_3 = 15\n",
        "\n",
        "nn2 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_layer_1, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_layer_2, activation=\"relu\"))\n",
        "\n",
        "# third hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_layer_3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAC28ane-c0l",
        "outputId": "b62355ce-9f94-43e5-f5fc-811badbf176f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 80)                2800      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 15)                465       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5711 (22.31 KB)\n",
            "Trainable params: 5711 (22.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ieQEHDIP-c7w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn2.fit(X_train_scaled, y_train, epochs=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIbSj6fK_T8Z",
        "outputId": "63248ae4-2fae-4c22-abc4-480b2d216e84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/88\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 0.5103 - accuracy: 0.8251\n",
            "Epoch 2/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8383\n",
            "Epoch 3/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8383\n",
            "Epoch 4/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8498\n",
            "Epoch 5/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8719\n",
            "Epoch 6/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3090 - accuracy: 0.8799\n",
            "Epoch 7/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.8843\n",
            "Epoch 8/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8940\n",
            "Epoch 9/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.8949\n",
            "Epoch 10/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.9019\n",
            "Epoch 11/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.8984\n",
            "Epoch 12/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.9117\n",
            "Epoch 13/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.9099\n",
            "Epoch 14/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.9108\n",
            "Epoch 15/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9214\n",
            "Epoch 16/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.9196\n",
            "Epoch 17/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9205\n",
            "Epoch 18/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9223\n",
            "Epoch 19/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9329\n",
            "Epoch 20/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9355\n",
            "Epoch 21/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9399\n",
            "Epoch 22/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9399\n",
            "Epoch 23/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9399\n",
            "Epoch 24/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9488\n",
            "Epoch 25/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9496\n",
            "Epoch 26/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9488\n",
            "Epoch 27/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9576\n",
            "Epoch 28/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9549\n",
            "Epoch 29/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9629\n",
            "Epoch 30/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9700\n",
            "Epoch 31/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9700\n",
            "Epoch 32/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9682\n",
            "Epoch 33/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9761\n",
            "Epoch 34/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9717\n",
            "Epoch 35/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9753\n",
            "Epoch 36/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9788\n",
            "Epoch 37/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9850\n",
            "Epoch 38/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9797\n",
            "Epoch 39/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9823\n",
            "Epoch 40/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9876\n",
            "Epoch 41/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9867\n",
            "Epoch 42/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9876\n",
            "Epoch 43/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9867\n",
            "Epoch 44/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9894\n",
            "Epoch 45/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9903\n",
            "Epoch 46/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9920\n",
            "Epoch 47/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9894\n",
            "Epoch 48/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9938\n",
            "Epoch 49/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9947\n",
            "Epoch 50/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9956\n",
            "Epoch 51/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9947\n",
            "Epoch 52/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9965\n",
            "Epoch 53/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9956\n",
            "Epoch 54/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9938\n",
            "Epoch 55/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9973\n",
            "Epoch 56/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9982\n",
            "Epoch 57/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9982\n",
            "Epoch 58/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9982\n",
            "Epoch 59/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 0.9991\n",
            "Epoch 60/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9991\n",
            "Epoch 61/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9991\n",
            "Epoch 62/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.9991\n",
            "Epoch 63/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 0.9991\n",
            "Epoch 64/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 65/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 66/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 0.9973\n",
            "Epoch 67/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 68/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 69/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 70/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 71/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 72/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 73/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 74/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 75/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 76/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 77/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 78/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 79/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 80/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 81/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 82/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 83/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 84/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 85/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 86/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 87/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 88/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BugPpgJl-dDX",
        "outputId": "dcba9c24-8128-4f5f-9277-3ca7b991c5f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 1.4239 - accuracy: 0.8134 - 98ms/epoch - 11ms/step\n",
            "Loss: 1.4238780736923218, Accuracy: 0.8133803009986877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization #3\n",
        "- change 2nd hidden layer activation to 'tanh'\n",
        "- Tanh is non-linear which means it models complex relationships well.  At the same time it also centers the activations around 0 which it makes it easier for subsequent layers to learn since the gradients will not be skewed towards one direction.\n",
        "- chose to do this on the second layer because Relu is an efficient, solid activation method that can reduce redundancy.  I want to let Relu \"set the tone\" and then see what the change to tanh will do."
      ],
      "metadata": {
        "id": "MLoJ6WPXAYno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input_dimensions = len(X_train_scaled[0])\n",
        "hidden_layer_1 = 80\n",
        "hidden_layer_2 = 30\n",
        "hidden_layer_3 = 15\n",
        "\n",
        "nn3 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn3.add(tf.keras.layers.Dense(units=hidden_layer_1, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn3.add(tf.keras.layers.Dense(units=hidden_layer_2, activation=\"tanh\"))\n",
        "\n",
        "# third hidden layer\n",
        "nn3.add(tf.keras.layers.Dense(units=hidden_layer_3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVe6AA-h-crJ",
        "outputId": "c1079b5b-72e1-4c03-d080-3788270d9fc3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 80)                2800      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 15)                465       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5711 (22.31 KB)\n",
            "Trainable params: 5711 (22.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZE7a-xtNAcVq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn3.fit(X_train_scaled, y_train, epochs=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlN0pJP2AcOE",
        "outputId": "9ac1402e-1b1c-4f7d-98d5-ebdf995b112d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/88\n",
            "36/36 [==============================] - 1s 1ms/step - loss: 0.4635 - accuracy: 0.8286\n",
            "Epoch 2/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8383\n",
            "Epoch 3/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8383\n",
            "Epoch 4/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8392\n",
            "Epoch 5/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8542\n",
            "Epoch 6/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3136 - accuracy: 0.8684\n",
            "Epoch 7/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8852\n",
            "Epoch 8/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.8869\n",
            "Epoch 9/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.8896\n",
            "Epoch 10/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2666 - accuracy: 0.9002\n",
            "Epoch 11/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2569 - accuracy: 0.9011\n",
            "Epoch 12/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.9019\n",
            "Epoch 13/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.9011\n",
            "Epoch 14/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9125\n",
            "Epoch 15/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9117\n",
            "Epoch 16/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9214\n",
            "Epoch 17/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.9249\n",
            "Epoch 18/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9320\n",
            "Epoch 19/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9346\n",
            "Epoch 20/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9408\n",
            "Epoch 21/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9399\n",
            "Epoch 22/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9470\n",
            "Epoch 23/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9558\n",
            "Epoch 24/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9549\n",
            "Epoch 25/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9532\n",
            "Epoch 26/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9514\n",
            "Epoch 27/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9638\n",
            "Epoch 28/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9664\n",
            "Epoch 29/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9673\n",
            "Epoch 30/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9682\n",
            "Epoch 31/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9744\n",
            "Epoch 32/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9735\n",
            "Epoch 33/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9797\n",
            "Epoch 34/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9770\n",
            "Epoch 35/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9814\n",
            "Epoch 36/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9823\n",
            "Epoch 37/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9823\n",
            "Epoch 38/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9850\n",
            "Epoch 39/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9841\n",
            "Epoch 40/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9885\n",
            "Epoch 41/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9850\n",
            "Epoch 42/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9850\n",
            "Epoch 43/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9903\n",
            "Epoch 44/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9973\n",
            "Epoch 45/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9929\n",
            "Epoch 46/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9947\n",
            "Epoch 47/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9973\n",
            "Epoch 48/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9965\n",
            "Epoch 49/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9982\n",
            "Epoch 50/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9973\n",
            "Epoch 51/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9982\n",
            "Epoch 52/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9991\n",
            "Epoch 53/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9991\n",
            "Epoch 54/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9991\n",
            "Epoch 55/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9991\n",
            "Epoch 56/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9991\n",
            "Epoch 57/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 58/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 59/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 60/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 61/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 62/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 63/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 64/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 65/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 66/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 67/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 68/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 69/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 70/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 71/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 72/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 73/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 74/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 75/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 76/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 77/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 9.9106e-04 - accuracy: 1.0000\n",
            "Epoch 78/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 9.4561e-04 - accuracy: 1.0000\n",
            "Epoch 79/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 9.6006e-04 - accuracy: 1.0000\n",
            "Epoch 80/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 8.7213e-04 - accuracy: 1.0000\n",
            "Epoch 81/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 8.0407e-04 - accuracy: 1.0000\n",
            "Epoch 82/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 7.6208e-04 - accuracy: 1.0000\n",
            "Epoch 83/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 7.2946e-04 - accuracy: 1.0000\n",
            "Epoch 84/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 7.0384e-04 - accuracy: 1.0000\n",
            "Epoch 85/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 6.8349e-04 - accuracy: 1.0000\n",
            "Epoch 86/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 6.2121e-04 - accuracy: 1.0000\n",
            "Epoch 87/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 5.9765e-04 - accuracy: 1.0000\n",
            "Epoch 88/88\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 5.6156e-04 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJKqipWCAcg0",
        "outputId": "ea7f2ca9-d26e-47a2-86a2-450a960fabec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 1.7315 - accuracy: 0.8134 - 98ms/epoch - 11ms/step\n",
            "Loss: 1.7315080165863037, Accuracy: 0.8133803009986877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization #4\n",
        "- change optimizer to 'RMSprop'\n",
        "- RMSprop leads to more stable and efficient optimization"
      ],
      "metadata": {
        "id": "tEEg3EaZA3dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input_dimensions = len(X_train_scaled[0])\n",
        "hidden_layer_1 = 80\n",
        "hidden_layer_2 = 30\n",
        "hidden_layer_3 = 15\n",
        "\n",
        "nn4 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn4.add(tf.keras.layers.Dense(units=hidden_layer_1, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn4.add(tf.keras.layers.Dense(units=hidden_layer_2, activation=\"tanh\"))\n",
        "\n",
        "# third hidden layer\n",
        "nn4.add(tf.keras.layers.Dense(units=hidden_layer_3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn4.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whEk9WMRA6z5",
        "outputId": "f3d10c7c-3999-49e5-dec5-e9aaf2daba5d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 80)                2800      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 15)                465       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5711 (22.31 KB)\n",
            "Trainable params: 5711 (22.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn4.compile(loss=\"binary_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "p3xfzLQWA679"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn4.fit(X_train_scaled, y_train, epochs=88)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4fhex54A7Cj",
        "outputId": "ac1c14f5-dae2-48fd-86af-5b17866271df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8383\n",
            "Epoch 2/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8383\n",
            "Epoch 3/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8383\n",
            "Epoch 4/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8383\n",
            "Epoch 5/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8383\n",
            "Epoch 6/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8383\n",
            "Epoch 7/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8383\n",
            "Epoch 8/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8383\n",
            "Epoch 9/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8383\n",
            "Epoch 10/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8383\n",
            "Epoch 11/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8383\n",
            "Epoch 12/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8383\n",
            "Epoch 13/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8383\n",
            "Epoch 14/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8383\n",
            "Epoch 15/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8383\n",
            "Epoch 16/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8383\n",
            "Epoch 17/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8383\n",
            "Epoch 18/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8383\n",
            "Epoch 19/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8383\n",
            "Epoch 20/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8383\n",
            "Epoch 21/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8383\n",
            "Epoch 22/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8383\n",
            "Epoch 23/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8383\n",
            "Epoch 24/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8383\n",
            "Epoch 25/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8383\n",
            "Epoch 26/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8383\n",
            "Epoch 27/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8383\n",
            "Epoch 28/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8383\n",
            "Epoch 29/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8383\n",
            "Epoch 30/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8383\n",
            "Epoch 31/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8383\n",
            "Epoch 32/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8383\n",
            "Epoch 33/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8383\n",
            "Epoch 34/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8383\n",
            "Epoch 35/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8383\n",
            "Epoch 36/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8383\n",
            "Epoch 37/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8383\n",
            "Epoch 38/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8383\n",
            "Epoch 39/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8383\n",
            "Epoch 40/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8383\n",
            "Epoch 41/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8383\n",
            "Epoch 42/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8383\n",
            "Epoch 43/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8383\n",
            "Epoch 44/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8383\n",
            "Epoch 45/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8383\n",
            "Epoch 46/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8383\n",
            "Epoch 47/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8383\n",
            "Epoch 48/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8383\n",
            "Epoch 49/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8392\n",
            "Epoch 50/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8392\n",
            "Epoch 51/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8392\n",
            "Epoch 52/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8392\n",
            "Epoch 53/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8392\n",
            "Epoch 54/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8392\n",
            "Epoch 55/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8392\n",
            "Epoch 56/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8392\n",
            "Epoch 57/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8392\n",
            "Epoch 58/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8392\n",
            "Epoch 59/88\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8392\n",
            "Epoch 60/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8392\n",
            "Epoch 61/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8392\n",
            "Epoch 62/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8392\n",
            "Epoch 63/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8392\n",
            "Epoch 64/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8392\n",
            "Epoch 65/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8392\n",
            "Epoch 66/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8392\n",
            "Epoch 67/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8392\n",
            "Epoch 68/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8392\n",
            "Epoch 69/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8392\n",
            "Epoch 70/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8392\n",
            "Epoch 71/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8392\n",
            "Epoch 72/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8392\n",
            "Epoch 73/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8392\n",
            "Epoch 74/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8401\n",
            "Epoch 75/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8401\n",
            "Epoch 76/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8401\n",
            "Epoch 77/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8401\n",
            "Epoch 78/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8410\n",
            "Epoch 79/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8410\n",
            "Epoch 80/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8410\n",
            "Epoch 81/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8419\n",
            "Epoch 82/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8419\n",
            "Epoch 83/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8428\n",
            "Epoch 84/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8428\n",
            "Epoch 85/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8428\n",
            "Epoch 86/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8428\n",
            "Epoch 87/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8428\n",
            "Epoch 88/88\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19fUR5SZA7I_",
        "outputId": "35868c4b-729a-4343-88fe-0b43a24f0a0c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 0.6574 - accuracy: 0.6937 - 158ms/epoch - 18ms/step\n",
            "Loss: 0.6573955416679382, Accuracy: 0.6936619877815247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization #5\n",
        "- increase epochs to 150 because the model never made it past 0.84298"
      ],
      "metadata": {
        "id": "7zBaNfZMEkie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input_dimensions = len(X_train_scaled[0])\n",
        "hidden_layer_1 = 80\n",
        "hidden_layer_2 = 30\n",
        "hidden_layer_3 = 15\n",
        "\n",
        "nn5 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn5.add(tf.keras.layers.Dense(units=hidden_layer_1, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn5.add(tf.keras.layers.Dense(units=hidden_layer_2, activation=\"tanh\", input_dim=input_dimensions))\n",
        "\n",
        "# third hidden layer\n",
        "nn5.add(tf.keras.layers.Dense(units=hidden_layer_3, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Output layer\n",
        "nn5.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zliLLhmdEoKH",
        "outputId": "d1902e51-c5f0-485b-ae62-6ad32fab66db"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 80)                2800      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 15)                465       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5711 (22.31 KB)\n",
            "Trainable params: 5711 (22.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn5.compile(loss=\"binary_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "G2zDdpwFEoRJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn5.fit(X_train_scaled, y_train, epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VsLnOzMEoYU",
        "outputId": "5b7f0f49-bb58-4fae-b2b2-d041513800dd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 0.4230 - accuracy: 0.8375\n",
            "Epoch 2/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8392\n",
            "Epoch 3/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8542\n",
            "Epoch 4/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8622\n",
            "Epoch 5/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3146 - accuracy: 0.8754\n",
            "Epoch 6/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8772\n",
            "Epoch 7/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8896\n",
            "Epoch 8/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8834\n",
            "Epoch 9/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2894 - accuracy: 0.8913\n",
            "Epoch 10/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.8922\n",
            "Epoch 11/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.8922\n",
            "Epoch 12/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8984\n",
            "Epoch 13/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8984\n",
            "Epoch 14/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.9037\n",
            "Epoch 15/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8984\n",
            "Epoch 16/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.9011\n",
            "Epoch 17/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.9081\n",
            "Epoch 18/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9090\n",
            "Epoch 19/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9108\n",
            "Epoch 20/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.9081\n",
            "Epoch 21/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9161\n",
            "Epoch 22/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9143\n",
            "Epoch 23/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9170\n",
            "Epoch 24/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9240\n",
            "Epoch 25/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.9134\n",
            "Epoch 26/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9231\n",
            "Epoch 27/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9223\n",
            "Epoch 28/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9205\n",
            "Epoch 29/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9276\n",
            "Epoch 30/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9240\n",
            "Epoch 31/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9329\n",
            "Epoch 32/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9408\n",
            "Epoch 33/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9382\n",
            "Epoch 34/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9435\n",
            "Epoch 35/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9390\n",
            "Epoch 36/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9417\n",
            "Epoch 37/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9470\n",
            "Epoch 38/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9479\n",
            "Epoch 39/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9443\n",
            "Epoch 40/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9558\n",
            "Epoch 41/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9505\n",
            "Epoch 42/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9470\n",
            "Epoch 43/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9585\n",
            "Epoch 44/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9479\n",
            "Epoch 45/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9514\n",
            "Epoch 46/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9594\n",
            "Epoch 47/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9602\n",
            "Epoch 48/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9682\n",
            "Epoch 49/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9567\n",
            "Epoch 50/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9594\n",
            "Epoch 51/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9638\n",
            "Epoch 52/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9655\n",
            "Epoch 53/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9673\n",
            "Epoch 54/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9611\n",
            "Epoch 55/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9691\n",
            "Epoch 56/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9753\n",
            "Epoch 57/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9735\n",
            "Epoch 58/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9700\n",
            "Epoch 59/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9735\n",
            "Epoch 60/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9664\n",
            "Epoch 61/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9753\n",
            "Epoch 62/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9700\n",
            "Epoch 63/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9806\n",
            "Epoch 64/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9770\n",
            "Epoch 65/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9823\n",
            "Epoch 66/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9788\n",
            "Epoch 67/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9797\n",
            "Epoch 68/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9867\n",
            "Epoch 69/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9779\n",
            "Epoch 70/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9832\n",
            "Epoch 71/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9779\n",
            "Epoch 72/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9859\n",
            "Epoch 73/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9832\n",
            "Epoch 74/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9823\n",
            "Epoch 75/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9832\n",
            "Epoch 76/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9859\n",
            "Epoch 77/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9850\n",
            "Epoch 78/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9850\n",
            "Epoch 79/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9894\n",
            "Epoch 80/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9859\n",
            "Epoch 81/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9850\n",
            "Epoch 82/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9850\n",
            "Epoch 83/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9876\n",
            "Epoch 84/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9850\n",
            "Epoch 85/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9867\n",
            "Epoch 86/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9876\n",
            "Epoch 87/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9885\n",
            "Epoch 88/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9885\n",
            "Epoch 89/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9912\n",
            "Epoch 90/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9938\n",
            "Epoch 91/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9894\n",
            "Epoch 92/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9894\n",
            "Epoch 93/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9841\n",
            "Epoch 94/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9912\n",
            "Epoch 95/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9929\n",
            "Epoch 96/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9938\n",
            "Epoch 97/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9920\n",
            "Epoch 98/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9929\n",
            "Epoch 99/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9929\n",
            "Epoch 100/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9912\n",
            "Epoch 101/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9920\n",
            "Epoch 102/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9956\n",
            "Epoch 103/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9938\n",
            "Epoch 104/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9929\n",
            "Epoch 105/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9965\n",
            "Epoch 106/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9938\n",
            "Epoch 107/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9912\n",
            "Epoch 108/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9912\n",
            "Epoch 109/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9965\n",
            "Epoch 110/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 0.9982\n",
            "Epoch 111/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9912\n",
            "Epoch 112/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.9982\n",
            "Epoch 113/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9912\n",
            "Epoch 114/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 0.9991\n",
            "Epoch 115/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9956\n",
            "Epoch 116/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9920\n",
            "Epoch 117/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9947\n",
            "Epoch 119/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.9947\n",
            "Epoch 121/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.9982\n",
            "Epoch 122/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 0.9973\n",
            "Epoch 123/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9991\n",
            "Epoch 125/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 0.9973\n",
            "Epoch 126/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.9965\n",
            "Epoch 127/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9973\n",
            "Epoch 129/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 0.9956\n",
            "Epoch 130/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 8.0165e-04 - accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.9982\n",
            "Epoch 132/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9947\n",
            "Epoch 133/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 8.2610e-04 - accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.9982\n",
            "Epoch 135/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 136/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9965\n",
            "Epoch 137/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 139/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 8.4062e-04 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9965\n",
            "Epoch 142/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 3.7570e-04 - accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.9982\n",
            "Epoch 144/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 0.9965\n",
            "Epoch 146/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.9973\n",
            "Epoch 147/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 2.4534e-04 - accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.9982\n",
            "Epoch 149/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 3.6538e-04 - accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoHhPxKLEodR",
        "outputId": "050a73e2-5371-4e13-8bdc-44a93afc0211"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 2.3700 - accuracy: 0.8134 - 106ms/epoch - 12ms/step\n",
            "Loss: 2.3699564933776855, Accuracy: 0.8133803009986877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization #6\n",
        "- Change optimizer to 'adagrad' because it's effective for training models with sparse data or high-dimensional feature spaces"
      ],
      "metadata": {
        "id": "SwTW_MMRG8An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input_dimensions = len(X_train_scaled[0])\n",
        "hidden_layer_1 = 80\n",
        "hidden_layer_2 = 30\n",
        "hidden_layer_3 = 15\n",
        "\n",
        "nn6 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn6.add(tf.keras.layers.Dense(units=hidden_layer_1, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn6.add(tf.keras.layers.Dense(units=hidden_layer_2, activation=\"tanh\", input_dim=input_dimensions))\n",
        "\n",
        "# third hidden layer\n",
        "nn6.add(tf.keras.layers.Dense(units=hidden_layer_3, activation=\"relu\", input_dim=input_dimensions))\n",
        "\n",
        "# Output layer\n",
        "nn6.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2ffb04-694c-4b18-93de-79ba6c7e2484",
        "id": "g-kjsnBEHT2a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 80)                2800      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 15)                465       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5711 (22.31 KB)\n",
            "Trainable params: 5711 (22.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn6.compile(loss=\"binary_crossentropy\", optimizer=\"adagrad\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "GRMJkOWxHC5y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn6.fit(X_train_scaled, y_train, epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg4jiUmSHDBv",
        "outputId": "f4218fc5-78f5-491d-821c-377f13d31379"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "36/36 [==============================] - 1s 1ms/step - loss: 0.7536 - accuracy: 0.2924\n",
            "Epoch 2/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.6714\n",
            "Epoch 3/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.6102 - accuracy: 0.8083\n",
            "Epoch 4/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.8322\n",
            "Epoch 5/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.8375\n",
            "Epoch 6/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.8392\n",
            "Epoch 7/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.8383\n",
            "Epoch 8/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8383\n",
            "Epoch 9/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.8383\n",
            "Epoch 10/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.8383\n",
            "Epoch 11/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8383\n",
            "Epoch 12/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.8383\n",
            "Epoch 13/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8383\n",
            "Epoch 14/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8383\n",
            "Epoch 15/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8383\n",
            "Epoch 16/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.8383\n",
            "Epoch 17/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8383\n",
            "Epoch 18/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8383\n",
            "Epoch 19/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8383\n",
            "Epoch 20/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8383\n",
            "Epoch 21/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8383\n",
            "Epoch 22/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8383\n",
            "Epoch 23/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8383\n",
            "Epoch 24/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8383\n",
            "Epoch 25/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8383\n",
            "Epoch 26/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8383\n",
            "Epoch 27/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8383\n",
            "Epoch 28/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8383\n",
            "Epoch 29/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4098 - accuracy: 0.8383\n",
            "Epoch 30/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8383\n",
            "Epoch 31/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4084 - accuracy: 0.8383\n",
            "Epoch 32/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8383\n",
            "Epoch 33/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8383\n",
            "Epoch 34/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8383\n",
            "Epoch 35/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8383\n",
            "Epoch 36/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.8383\n",
            "Epoch 37/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8383\n",
            "Epoch 38/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8383\n",
            "Epoch 39/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8383\n",
            "Epoch 40/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4030 - accuracy: 0.8383\n",
            "Epoch 41/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8383\n",
            "Epoch 42/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8383\n",
            "Epoch 43/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8383\n",
            "Epoch 44/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.8383\n",
            "Epoch 45/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8383\n",
            "Epoch 46/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8383\n",
            "Epoch 47/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8383\n",
            "Epoch 48/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.8383\n",
            "Epoch 49/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8383\n",
            "Epoch 50/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8383\n",
            "Epoch 51/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8383\n",
            "Epoch 52/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8383\n",
            "Epoch 53/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8383\n",
            "Epoch 54/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8383\n",
            "Epoch 55/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8383\n",
            "Epoch 56/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8383\n",
            "Epoch 57/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8383\n",
            "Epoch 58/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3933 - accuracy: 0.8383\n",
            "Epoch 59/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8383\n",
            "Epoch 60/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3922 - accuracy: 0.8383\n",
            "Epoch 61/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8383\n",
            "Epoch 62/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8383\n",
            "Epoch 63/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8383\n",
            "Epoch 64/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8383\n",
            "Epoch 65/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8383\n",
            "Epoch 66/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8383\n",
            "Epoch 67/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8383\n",
            "Epoch 68/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8383\n",
            "Epoch 69/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8383\n",
            "Epoch 70/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8383\n",
            "Epoch 71/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8383\n",
            "Epoch 72/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8383\n",
            "Epoch 73/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8383\n",
            "Epoch 74/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8383\n",
            "Epoch 75/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8383\n",
            "Epoch 76/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8383\n",
            "Epoch 77/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8383\n",
            "Epoch 78/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8383\n",
            "Epoch 79/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 0.8383\n",
            "Epoch 80/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8383\n",
            "Epoch 81/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.8383\n",
            "Epoch 82/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8383\n",
            "Epoch 83/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8383\n",
            "Epoch 84/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8383\n",
            "Epoch 85/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8383\n",
            "Epoch 86/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8392\n",
            "Epoch 87/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.8392\n",
            "Epoch 88/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8392\n",
            "Epoch 89/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8392\n",
            "Epoch 90/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8392\n",
            "Epoch 91/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8392\n",
            "Epoch 92/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8392\n",
            "Epoch 93/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8392\n",
            "Epoch 94/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8392\n",
            "Epoch 95/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8392\n",
            "Epoch 96/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8392\n",
            "Epoch 97/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8392\n",
            "Epoch 98/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8401\n",
            "Epoch 99/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8401\n",
            "Epoch 100/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8401\n",
            "Epoch 101/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8401\n",
            "Epoch 102/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8401\n",
            "Epoch 103/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8401\n",
            "Epoch 104/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8401\n",
            "Epoch 105/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8401\n",
            "Epoch 106/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8401\n",
            "Epoch 107/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8401\n",
            "Epoch 108/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8401\n",
            "Epoch 109/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8401\n",
            "Epoch 110/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8401\n",
            "Epoch 111/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8401\n",
            "Epoch 112/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8401\n",
            "Epoch 113/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8401\n",
            "Epoch 114/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8401\n",
            "Epoch 115/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8401\n",
            "Epoch 116/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8401\n",
            "Epoch 117/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8401\n",
            "Epoch 118/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8401\n",
            "Epoch 119/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8401\n",
            "Epoch 120/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8401\n",
            "Epoch 121/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8419\n",
            "Epoch 122/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8428\n",
            "Epoch 123/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8428\n",
            "Epoch 124/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8436\n",
            "Epoch 125/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8445\n",
            "Epoch 126/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8445\n",
            "Epoch 127/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8445\n",
            "Epoch 128/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8445\n",
            "Epoch 129/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8454\n",
            "Epoch 130/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8454\n",
            "Epoch 131/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8454\n",
            "Epoch 132/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8472\n",
            "Epoch 133/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8481\n",
            "Epoch 134/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8481\n",
            "Epoch 135/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8489\n",
            "Epoch 136/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8489\n",
            "Epoch 137/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8489\n",
            "Epoch 138/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8489\n",
            "Epoch 139/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8489\n",
            "Epoch 140/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8489\n",
            "Epoch 141/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8498\n",
            "Epoch 142/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8498\n",
            "Epoch 143/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8498\n",
            "Epoch 144/150\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8498\n",
            "Epoch 145/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8498\n",
            "Epoch 146/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8498\n",
            "Epoch 147/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8498\n",
            "Epoch 148/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8498\n",
            "Epoch 149/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8498\n",
            "Epoch 150/150\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMlna0sbHDH0",
        "outputId": "8082026f-486c-4a1d-99d2-f3562913fa05"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 0.3903 - accuracy: 0.8415 - 94ms/epoch - 10ms/step\n",
            "Loss: 0.39030468463897705, Accuracy: 0.841549277305603\n"
          ]
        }
      ]
    }
  ]
}